[io]
#a space seperated list of input names
inputs = features
#a space seperated list of output names
outputs = text

[encoder]
#type of encoder
encoder = dblstm
#the standard deviation of the Gaussian input noise added during training
input_noise = 0
#number of pyramidal layers a non-pyramidal layer is added at the end
num_layers = 2
#number of units in each layer
num_units = 128
#number of timesteps to concatenate in each pyramidal layer
pyramid_steps = 2
#dropout rate
dropout = 0.5

[decoder]
#type of decoder
decoder = speller
#number of layers
num_layers = 2
#number of units
num_units = 128
#wheter the entire state of the encoder should be used to query the atention or
#just the output
statequery = False
#the attention mechanism that should be used, one of vanilla, location_aware
#or monotonic
attention = windowed
left_window_width = 20
right_window_width = 30
num_iters = 2
#the probability functino that should be used for the alignments, one of
#softmax or sigmoid
probability_fn = softmax
#number of filters in the location aware attention
numfilt = 10
#the size of the location aware filters
filtersize = 100
#the probability that the network will sample from the output during training
sample_prob = 0.1
#the output dimensions
output_dims = 4716
